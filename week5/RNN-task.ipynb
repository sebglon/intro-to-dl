{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "RNN-task.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sebglon/intro-to-dl/blob/master/week5/RNN-task.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zgmz_1nA4NrO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "378c973a-47cd-443a-f507-82b6929878ea"
      },
      "source": [
        "! shred -u setup_google_colab.py\n",
        "! wget https://raw.githubusercontent.com/hse-aml/intro-to-dl/master/setup_google_colab.py -O setup_google_colab.py\n",
        "import setup_google_colab\n",
        "# please, uncomment the week you're working on\n",
        "# setup_google_colab.setup_week1()\n",
        "# setup_google_colab.setup_week2()\n",
        "# setup_google_colab.setup_week3()\n",
        "# setup_google_colab.setup_week4()\n",
        "setup_google_colab.setup_week5()\n",
        "# setup_google_colab.setup_week6()\n",
        "\n",
        "# If you're using the old version of the course (check a path of notebook on Coursera, you'll see v1 or v2),\n",
        "# use setup_week2_old().\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-11-13 22:57:16--  https://raw.githubusercontent.com/hse-aml/intro-to-dl/master/setup_google_colab.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3792 (3.7K) [text/plain]\n",
            "Saving to: ‘setup_google_colab.py’\n",
            "\n",
            "\rsetup_google_colab.   0%[                    ]       0  --.-KB/s               \rsetup_google_colab. 100%[===================>]   3.70K  --.-KB/s    in 0s      \n",
            "\n",
            "2019-11-13 22:57:16 (57.7 MB/s) - ‘setup_google_colab.py’ saved [3792/3792]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hLnc9bxj4J_X",
        "colab_type": "text"
      },
      "source": [
        "# Generating names with recurrent neural networks\n",
        "\n",
        "This time you'll find yourself delving into the heart (and other intestines) of recurrent neural networks on a class of toy problems.\n",
        "\n",
        "Struggle to find a name for the variable? Let's see how you'll come up with a name for your son/daughter. Surely no human has expertize over what is a good child name, so let us train RNN instead;\n",
        "\n",
        "It's dangerous to go alone, take these:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.696201Z",
          "start_time": "2018-08-13T20:26:38.104103Z"
        },
        "id": "UKBL17VJ4J_Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "9b6c7811-f51d-45e7-da61-d0d329087a05"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import os\n",
        "import sys\n",
        "sys.path.append(\"..\")\n",
        "import keras_utils\n",
        "import tqdm_utils"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.15.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XLv0ocXo4J_c",
        "colab_type": "text"
      },
      "source": [
        "# Load data\n",
        "The dataset contains ~8k earthling names from different cultures, all in latin transcript.\n",
        "\n",
        "This notebook has been designed so as to allow you to quickly swap names for something similar: deep learning article titles, IKEA furniture, pokemon names, etc."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.701832Z",
          "start_time": "2018-08-13T20:26:42.697766Z"
        },
        "id": "LQzu8R3-4J_d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "start_token = \" \"  # so that the network knows that we're generating a first token\n",
        "\n",
        "# this is the token for padding,\n",
        "# we will add fake pad token at the end of names \n",
        "# to make them of equal size for further batching\n",
        "pad_token = \"#\"\n",
        "\n",
        "with open(\"names\") as f:\n",
        "    names = f.read()[:-1].split('\\n')\n",
        "    names = [start_token + name for name in names]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.707885Z",
          "start_time": "2018-08-13T20:26:42.703302Z"
        },
        "id": "CIQ7tqx34J_i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "d91efc22-4e22-4399-e442-428fee2b9176"
      },
      "source": [
        "print('number of samples:', len(names))\n",
        "for x in names[::1000]:\n",
        "    print(x)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of samples: 7944\n",
            " Abagael\n",
            " Claresta\n",
            " Glory\n",
            " Liliane\n",
            " Prissie\n",
            " Geeta\n",
            " Giovanne\n",
            " Piggy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.857411Z",
          "start_time": "2018-08-13T20:26:42.709371Z"
        },
        "id": "za7fRYfZ4J_l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "outputId": "fbd830ee-8855-4613-bfd2-f601321a6caa"
      },
      "source": [
        "MAX_LENGTH = max(map(len, names))\n",
        "print(\"max length:\", MAX_LENGTH)\n",
        "\n",
        "plt.title('Sequence length distribution')\n",
        "plt.hist(list(map(len, names)), bins=25);"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "max length: 16\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEICAYAAACzliQjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQ9/MLCMOfTOzjPx/p/4cUF1Gcl0AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "evNfq0sa4J_o",
        "colab_type": "text"
      },
      "source": [
        "# Text processing\n",
        "\n",
        "First we need to collect a \"vocabulary\" of all unique tokens i.e. unique characters. We can then encode inputs as a sequence of character ids."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.864592Z",
          "start_time": "2018-08-13T20:26:42.858725Z"
        },
        "id": "IKN_hr9D4J_p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5173b49a-10bc-4c66-a686-7eb54ce37a96"
      },
      "source": [
        "tokens = list(set(pad_token.join(names)))### YOUR CODE HERE: all unique characters go here, padding included!\n",
        "\n",
        "tokens = list(tokens)\n",
        "n_tokens = len(tokens)\n",
        "print ('n_tokens:', n_tokens)\n",
        "\n",
        "assert 50 < n_tokens < 60"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "n_tokens: 56\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fZGqCMHK4J_s",
        "colab_type": "text"
      },
      "source": [
        "### Cast everything from symbols into identifiers\n",
        "\n",
        "Tensorflow string manipulation is a bit tricky, so we'll work around it. \n",
        "We'll feed our recurrent neural network with ids of characters from our dictionary.\n",
        "\n",
        "To create such dictionary, let's assign `token_to_id`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.870330Z",
          "start_time": "2018-08-13T20:26:42.866135Z"
        },
        "id": "YzyJuQxY4J_t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "token_to_id = {}### YOUR CODE HERE: create a dictionary of {symbol -> its  index in tokens}\n",
        "for index, token in enumerate(tokens):\n",
        "    token_to_id[token] = index\n",
        "    \n",
        "assert len(tokens) == len(token_to_id), \"dictionaries must have same size\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.875943Z",
          "start_time": "2018-08-13T20:26:42.871834Z"
        },
        "id": "BB2S3ri84J_x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def to_matrix(names, max_len=None, pad=token_to_id[pad_token], dtype=np.int32):\n",
        "    \"\"\"Casts a list of names into rnn-digestable padded matrix\"\"\"\n",
        "    \n",
        "    max_len = max_len or max(map(len, names))\n",
        "    names_ix = np.zeros([len(names), max_len], dtype) + pad\n",
        "\n",
        "    for i in range(len(names)):\n",
        "        name_ix = list(map(token_to_id.get, names[i]))\n",
        "        names_ix[i, :len(name_ix)] = name_ix\n",
        "\n",
        "    return names_ix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.883107Z",
          "start_time": "2018-08-13T20:26:42.877186Z"
        },
        "id": "q8LJGpmx4J_1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "3e9b458e-c50c-4bc2-8358-7d6fe1541194"
      },
      "source": [
        "# Example: cast 4 random names to padded matrices (so that we can easily batch them)\n",
        "print('\\n'.join(names[::2000]))\n",
        "print(to_matrix(names[::2000]))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Abagael\n",
            " Glory\n",
            " Prissie\n",
            " Giovanne\n",
            "[[ 0 15 53 44 45 44  9 21  4]\n",
            " [ 0 10 21  5 52 39  4  4  4]\n",
            " [ 0 26 52 28 32 32 28  9  4]\n",
            " [ 0 10 28  5  8 44 43 43  9]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3LliXsBi4J_3",
        "colab_type": "text"
      },
      "source": [
        "# Defining a recurrent neural network\n",
        "\n",
        "We can rewrite recurrent neural network as a consecutive application of dense layer to input $x_t$ and previous rnn state $h_t$. This is exactly what we're gonna do now.\n",
        "<img src=\"https://github.com/sebglon/intro-to-dl/blob/master/week5/rnn.png?raw=1\" width=600>\n",
        "\n",
        "Since we're training a language model, there should also be:\n",
        "* An embedding layer that converts character id x_t to a vector.\n",
        "* An output layer that predicts probabilities of next phoneme based on h_t+1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.039419Z",
          "start_time": "2018-08-13T20:26:42.884581Z"
        },
        "id": "JzLwCDQZ4J_4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "cb9cad0b-14b7-4491-ad67-2975c66a8a7b"
      },
      "source": [
        "# remember to reset your session if you change your graph!\n",
        "s = keras_utils.reset_tf_session()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /content/keras_utils.py:68: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:79: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:82: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:84: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/keras_utils.py:75: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/keras_utils.py:77: The name tf.InteractiveSession is deprecated. Please use tf.compat.v1.InteractiveSession instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.044903Z",
          "start_time": "2018-08-13T20:26:44.041084Z"
        },
        "id": "mFEs4koa4J_7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from keras.layers import concatenate, Dense, Embedding\n",
        "\n",
        "rnn_num_units = 64  # size of hidden state\n",
        "embedding_size = 16  # for characters\n",
        "\n",
        "# Let's create layers for our recurrent network\n",
        "# Note: we create layers but we don't \"apply\" them yet (this is a \"functional API\" of Keras)\n",
        "# Note: set the correct activation (from keras.activations) to Dense layers!\n",
        "\n",
        "# an embedding layer that converts character ids into embeddings\n",
        "embed_x = Embedding(n_tokens, embedding_size)\n",
        "\n",
        "# a dense layer that maps input and previous state to new hidden state, [x_t,h_t]->h_t+1\n",
        "get_h_next = Dense(rnn_num_units, activation = 'relu')\n",
        "\n",
        "# a dense layer that maps current hidden state to probabilities of characters [h_t+1]->P(x_t+1|h_t+1)\n",
        "get_probas = Dense(n_tokens, activation = 'softmax') ### YOUR CODE HERE "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w3677CAM4J_9",
        "colab_type": "text"
      },
      "source": [
        "We will generate names character by character starting with `start_token`:\n",
        "\n",
        "<img src=\"https://github.com/sebglon/intro-to-dl/blob/master/week5/char-nn.png?raw=1\" width=600>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.053212Z",
          "start_time": "2018-08-13T20:26:44.048389Z"
        },
        "id": "OWZ1PGTC4J_-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def rnn_one_step(x_t, h_t):\n",
        "    \"\"\"\n",
        "    Recurrent neural network step that produces \n",
        "    probabilities for next token x_t+1 and next state h_t+1\n",
        "    given current input x_t and previous state h_t.\n",
        "    We'll call this method repeatedly to produce the whole sequence.\n",
        "    \n",
        "    You're supposed to \"apply\" above layers to produce new tensors.\n",
        "    Follow inline instructions to complete the function.\n",
        "    \"\"\"\n",
        "    # convert character id into embedding\n",
        "    x_t_emb = embed_x(tf.reshape(x_t, [-1, 1]))[:, 0]\n",
        "    \n",
        "    # concatenate x_t embedding and previous h_t state\n",
        "    x_and_h = tf.concat([x_t_emb, h_t], 1)### YOUR CODE HERE\n",
        "    \n",
        "    # compute next state given x_and_h\n",
        "    h_next = get_h_next(x_and_h)### YOUR CODE HERE\n",
        "    \n",
        "    # get probabilities for language model P(x_next|h_next)\n",
        "    output_probas = get_probas(h_next)### YOUR CODE HERE\n",
        "    \n",
        "    return output_probas, h_next"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-k06h3HD4KAC",
        "colab_type": "text"
      },
      "source": [
        "# RNN: loop\n",
        "\n",
        "Once `rnn_one_step` is ready, let's apply it in a loop over name characters to get predictions.\n",
        "\n",
        "Let's assume that all names are at most length-16 for now, so we can simply iterate over them in a for loop.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.342948Z",
          "start_time": "2018-08-13T20:26:44.056136Z"
        },
        "id": "oO8ZLP8X4KAD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "e30500b7-46e0-4f21-f487-702646968dc2"
      },
      "source": [
        "input_sequence = tf.placeholder(tf.int32, (None, MAX_LENGTH))  # batch of token ids\n",
        "batch_size = tf.shape(input_sequence)[0]\n",
        "\n",
        "predicted_probas = []\n",
        "h_prev = tf.zeros([batch_size, rnn_num_units])  # initial hidden state\n",
        "\n",
        "for t in range(MAX_LENGTH):\n",
        "    x_t = input_sequence[:, t]  # column t\n",
        "    probas_next, h_next = rnn_one_step(x_t, h_prev)\n",
        "    \n",
        "    h_prev = h_next\n",
        "    predicted_probas.append(probas_next)\n",
        "    \n",
        "# combine predicted_probas into [batch, time, n_tokens] tensor\n",
        "predicted_probas = tf.transpose(tf.stack(predicted_probas), [1, 0, 2])\n",
        "\n",
        "# next to last token prediction is not needed\n",
        "predicted_probas = predicted_probas[:, :-1, :]"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3535: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j5Affff34KAG",
        "colab_type": "text"
      },
      "source": [
        "# RNN: loss and gradients\n",
        "\n",
        "Let's gather a matrix of predictions for $P(x_{next}|h)$ and the corresponding correct answers.\n",
        "\n",
        "We will flatten our matrices to shape [None, n_tokens] to make it easier.\n",
        "\n",
        "Our network can then be trained by minimizing crossentropy between predicted probabilities and those answers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.354310Z",
          "start_time": "2018-08-13T20:26:44.344648Z"
        },
        "id": "tjPeeFy-4KAH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# flatten predictions to [batch*time, n_tokens]\n",
        "predictions_matrix = tf.reshape(predicted_probas, [-1, n_tokens])\n",
        "\n",
        "# flatten answers (next tokens) and one-hot encode them\n",
        "answers_matrix = tf.one_hot(tf.reshape(input_sequence[:, 1:], [-1]), n_tokens)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "44t3CEaA4KAJ",
        "colab_type": "text"
      },
      "source": [
        "Usually it's a good idea to ignore gradients of loss for padding token predictions.\n",
        "\n",
        "Because we don't care about further prediction after the pad_token is predicted for the first time, so it doesn't make sense to punish our network after the pad_token is predicted.\n",
        "\n",
        "For simplicity you can ignore this comment, it's up to you."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:45.076642Z",
          "start_time": "2018-08-13T20:26:44.355594Z"
        },
        "id": "iZ1ifR0K4KAK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "b348ed5e-ecc5-4427-ac3a-15f4106809d0"
      },
      "source": [
        "# Define the loss as categorical cross-entropy (e.g. from keras.losses).\n",
        "# Mind that predictions are probabilities and NOT logits!\n",
        "# Remember to apply tf.reduce_mean to get a scalar loss!\n",
        "from keras.objectives import categorical_crossentropy\n",
        "\n",
        "loss = tf.reduce_mean(categorical_crossentropy(answers_matrix, predictions_matrix)) ### YOUR CODE HERE\n",
        "\n",
        "optimize = tf.train.AdamOptimizer().minimize(loss)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2745: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "keep_dims is deprecated, use keepdims instead\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2749: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QMKMyeYE4KAM",
        "colab_type": "text"
      },
      "source": [
        "# RNN: training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:55.322187Z",
          "start_time": "2018-08-13T20:26:45.078296Z"
        },
        "id": "OYaotxEO4KAN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "6cb59262-aeff-424c-c896-df6215d1716f"
      },
      "source": [
        "from IPython.display import clear_output\n",
        "from random import sample\n",
        "\n",
        "s.run(tf.global_variables_initializer())\n",
        "\n",
        "batch_size = 32\n",
        "history = []\n",
        "\n",
        "for i in range(1000):\n",
        "    batch = to_matrix(sample(names, batch_size), max_len=MAX_LENGTH)\n",
        "    loss_i, _ = s.run([loss, optimize], {input_sequence: batch})\n",
        "    \n",
        "    history.append(loss_i)\n",
        "    \n",
        "    if (i + 1) % 100 == 0:\n",
        "        clear_output(True)\n",
        "        plt.plot(history, label='loss')\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n",
        "assert np.mean(history[:10]) > np.mean(history[-10:]), \"RNN didn't converge\""
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oO6I3D844KAQ",
        "colab_type": "text"
      },
      "source": [
        "# RNN: sampling\n",
        "Once we've trained our network a bit, let's get to actually generating stuff. All we need is the `rnn_one_step` function you have written above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:55.341196Z",
          "start_time": "2018-08-13T20:26:55.323787Z"
        },
        "id": "w3nmhISZ4KAR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_t = tf.placeholder(tf.int32, (1,))\n",
        "h_t = tf.Variable(np.zeros([1, rnn_num_units], np.float32))  # we will update hidden state in this variable\n",
        "\n",
        "# For sampling we need to define `rnn_one_step` tensors only once in our graph.\n",
        "# We reuse all parameters thanks to functional API usage.\n",
        "# Then we can feed appropriate tensor values using feed_dict in a loop.\n",
        "# Note how different it is from training stage, where we had to unroll the whole sequence for backprop.\n",
        "next_probs, next_h = rnn_one_step(x_t, h_t)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:55.346422Z",
          "start_time": "2018-08-13T20:26:55.342659Z"
        },
        "id": "eq7vJz3V4KAU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_sample(seed_phrase=start_token, max_length=MAX_LENGTH):\n",
        "    '''\n",
        "    This function generates text given a `seed_phrase` as a seed.\n",
        "    Remember to include start_token in seed phrase!\n",
        "    Parameter `max_length` is used to set the number of characters in prediction.\n",
        "    '''\n",
        "    x_sequence = [token_to_id[token] for token in seed_phrase]\n",
        "    s.run(tf.assign(h_t, h_t.initial_value))\n",
        "    \n",
        "    # feed the seed phrase, if any\n",
        "    for ix in x_sequence[:-1]:\n",
        "         s.run(tf.assign(h_t, next_h), {x_t: [ix]})\n",
        "    \n",
        "    # start generating\n",
        "    for _ in range(max_length-len(seed_phrase)):\n",
        "        x_probs,_ = s.run([next_probs, tf.assign(h_t, next_h)], {x_t: [x_sequence[-1]]})\n",
        "        x_sequence.append(np.random.choice(n_tokens, p=x_probs[0]))\n",
        "        \n",
        "    return ''.join([tokens[ix] for ix in x_sequence if tokens[ix] != pad_token])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:58.458115Z",
          "start_time": "2018-08-13T20:26:55.347900Z"
        },
        "id": "SXoALRmr4KAY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "44175632-4f77-45b1-aaf0-eaf837af6d5f"
      },
      "source": [
        "# without prefix\n",
        "for _ in range(10):\n",
        "    print(generate_sample())"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Gorioe\n",
            " Riceere\n",
            " Cobai\n",
            " Jusedil\n",
            " Sbemwal\n",
            " Tolur\n",
            " Tyata\n",
            " Mamulty\n",
            " Warrirw\n",
            " Brtinso\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:27:01.986726Z",
          "start_time": "2018-08-13T20:26:58.459810Z"
        },
        "id": "LZ9sujIx4KAc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "5ada5096-02fb-40cd-a7a7-0135823f77a6"
      },
      "source": [
        "# with prefix conditioning\n",
        "for _ in range(10):\n",
        "    print(generate_sample(' Trump'))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Trumpar\n",
            " Trumpala\n",
            " Trumpine\n",
            " Trumpele\n",
            " Trumpar\n",
            " Trumpy\n",
            " Trumphire\n",
            " Trumpyb\n",
            " Trump\n",
            " Trumpher\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-1iadlvW4KAe",
        "colab_type": "text"
      },
      "source": [
        "# Submit to Coursera"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:40:02.004926Z",
          "start_time": "2018-08-13T20:40:02.000821Z"
        },
        "id": "XHdnF8Sn4KAf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# token expires every 30 min\n",
        "COURSERA_TOKEN = \"iN7GE6QUEYOIRaEr\"\n",
        "COURSERA_EMAIL = \"sebglon@gmail.com\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:40:18.923357Z",
          "start_time": "2018-08-13T20:40:03.549343Z"
        },
        "id": "2hrNX9i64KAj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "7a07fedd-4949-413d-ead9-f63b76041b83"
      },
      "source": [
        "from submit import submit_char_rnn\n",
        "samples = [generate_sample(' Al') for i in tqdm_utils.tqdm_notebook_failsafe(range(25))]\n",
        "submission = (history, samples)\n",
        "submit_char_rnn(submission, COURSERA_EMAIL, COURSERA_TOKEN)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "*************************\n",
            "\n",
            "Submitted to Coursera platform. See results on assignment page!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r5XpIk9K4KAl",
        "colab_type": "text"
      },
      "source": [
        "# Try it out!\n",
        "\n",
        "__Disclaimer:__ This part of assignment is entirely optional. You won't receive bonus points for it. However, it's a fun thing to do. Please share your results on course forums.\n",
        "\n",
        "You've just implemented a recurrent language model that can be tasked with generating any kind of sequence, so there's plenty of data you can try it on:\n",
        "\n",
        "* Novels/poems/songs of your favorite author\n",
        "* News titles/clickbait titles\n",
        "* Source code of Linux or Tensorflow\n",
        "* Molecules in [smiles](https://en.wikipedia.org/wiki/Simplified_molecular-input_line-entry_system) format\n",
        "* Melody in notes/chords format\n",
        "* IKEA catalog titles\n",
        "* Pokemon names\n",
        "* Cards from Magic, the Gathering / Hearthstone\n",
        "\n",
        "If you're willing to give it a try, here's what you wanna look at:\n",
        "* Current data format is a sequence of lines, so a novel can be formatted as a list of sentences. Alternatively, you can change data preprocessing altogether.\n",
        "* While some datasets are readily available, others can only be scraped from the web. Try `Selenium` or `Scrapy` for that.\n",
        "* Make sure MAX_LENGTH is adjusted for longer datasets. There's also a bonus section about dynamic RNNs at the bottom.\n",
        "* More complex tasks require larger RNN architecture, try more neurons or several layers. It would also require more training iterations.\n",
        "* Long-term dependencies in music, novels or molecules are better handled with LSTM or GRU\n",
        "\n",
        "__Good hunting!__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "o-pFfIt54KAm",
        "colab_type": "text"
      },
      "source": [
        "# Bonus level: dynamic RNNs\n",
        "\n",
        "Apart from Keras, there's also a friendly TensorFlow API for recurrent neural nets. It's based around the symbolic loop function (aka [tf.scan](https://www.tensorflow.org/api_docs/python/tf/scan)).\n",
        "\n",
        "RNN loop that we implemented for training can be replaced with single TensorFlow instruction: [tf.nn.dynamic_rnn](https://www.tensorflow.org/api_docs/python/tf/nn/dynamic_rnn).\n",
        "This interface allows for dynamic sequence length and comes with some pre-implemented architectures.\n",
        "\n",
        "Take a look at [tf.nn.rnn_cell.BasicRNNCell](https://www.tensorflow.org/api_docs/python/tf/contrib/rnn/BasicRNNCell)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:27:12.975354Z",
          "start_time": "2018-08-13T20:27:12.737529Z"
        },
        "id": "aNetM0Ov4KAm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "outputId": "d19abc78-7fe2-414d-a264-ffd8f0616475"
      },
      "source": [
        "class CustomRNN(tf.nn.rnn_cell.BasicRNNCell):\n",
        "    def call(self, input, state):\n",
        "        # from docs:\n",
        "        # Returns:\n",
        "        # Output: A 2-D tensor with shape [batch_size, self.output_size].\n",
        "        # New state: Either a single 2-D tensor, or a tuple of tensors matching the arity and shapes of state.\n",
        "        return rnn_one_step(input[:, 0], state)\n",
        "    \n",
        "    @property\n",
        "    def output_size(self):\n",
        "        return n_tokens\n",
        "    \n",
        "cell = CustomRNN(rnn_num_units)\n",
        "\n",
        "input_sequence = tf.placeholder(tf.int32, (None, None))\n",
        "    \n",
        "predicted_probas, last_state = tf.nn.dynamic_rnn(cell, input_sequence[:, :, None], dtype=tf.float32)\n",
        "\n",
        "print('LSTM outputs for each step [batch,time,n_tokens]:')\n",
        "print(predicted_probas.eval({input_sequence: to_matrix(names[:10], max_len=50)}).shape)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-23-5f3812e903bf>:13: BasicRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.SimpleRNNCell, and will be replaced by that in Tensorflow 2.0.\n",
            "WARNING:tensorflow:From <ipython-input-23-5f3812e903bf>:17: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-5f3812e903bf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0minput_sequence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mpredicted_probas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdynamic_rnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_sequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'LSTM outputs for each step [batch,time,n_tokens]:'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m               \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m               instructions)\n\u001b[0;32m--> 324\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m     return tf_decorator.make_decorator(\n\u001b[1;32m    326\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'deprecated'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn.py\u001b[0m in \u001b[0;36mdynamic_rnn\u001b[0;34m(cell, inputs, sequence_length, initial_state, dtype, parallel_iterations, swap_memory, time_major, scope)\u001b[0m\n\u001b[1;32m    705\u001b[0m         \u001b[0mswap_memory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswap_memory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m         \u001b[0msequence_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msequence_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 707\u001b[0;31m         dtype=dtype)\n\u001b[0m\u001b[1;32m    708\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m     \u001b[0;31m# Outputs of _dynamic_rnn_loop are always shaped [time, batch, depth].\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn.py\u001b[0m in \u001b[0;36m_dynamic_rnn_loop\u001b[0;34m(cell, inputs, initial_state, parallel_iterations, swap_memory, sequence_length, dtype)\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0mparallel_iterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparallel_iterations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0mmaximum_iterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtime_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 916\u001b[0;31m       swap_memory=swap_memory)\n\u001b[0m\u001b[1;32m    917\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    918\u001b[0m   \u001b[0;31m# Unpack final output if not using output tuples.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36mwhile_loop\u001b[0;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, name, maximum_iterations, return_same_structure)\u001b[0m\n\u001b[1;32m   2751\u001b[0m       \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_to_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraphKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWHILE_CONTEXT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloop_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2752\u001b[0m     result = loop_context.BuildLoop(cond, body, loop_vars, shape_invariants,\n\u001b[0;32m-> 2753\u001b[0;31m                                     return_same_structure)\n\u001b[0m\u001b[1;32m   2754\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmaximum_iterations\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2755\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36mBuildLoop\u001b[0;34m(self, pred, body, loop_vars, shape_invariants, return_same_structure)\u001b[0m\n\u001b[1;32m   2243\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mutation_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2244\u001b[0m         original_body_result, exit_vars = self._BuildLoop(\n\u001b[0;32m-> 2245\u001b[0;31m             pred, body, original_loop_vars, loop_vars, shape_invariants)\n\u001b[0m\u001b[1;32m   2246\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2247\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36m_BuildLoop\u001b[0;34m(self, pred, body, original_loop_vars, loop_vars, shape_invariants)\u001b[0m\n\u001b[1;32m   2168\u001b[0m         expand_composites=True)\n\u001b[1;32m   2169\u001b[0m     \u001b[0mpre_summaries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraphKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_SUMMARY_COLLECTION\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2170\u001b[0;31m     \u001b[0mbody_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpacked_vars_for_body\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2171\u001b[0m     \u001b[0mpost_summaries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraphKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_SUMMARY_COLLECTION\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2172\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_sequence_or_composite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody_result\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(i, lv)\u001b[0m\n\u001b[1;32m   2703\u001b[0m         cond = lambda i, lv: (  # pylint: disable=g-long-lambda\n\u001b[1;32m   2704\u001b[0m             math_ops.logical_and(i < maximum_iterations, orig_cond(*lv)))\n\u001b[0;32m-> 2705\u001b[0;31m         \u001b[0mbody\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlv\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig_body\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2706\u001b[0m       \u001b[0mtry_to_pack\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn.py\u001b[0m in \u001b[0;36m_time_step\u001b[0;34m(time, output_ta_t, state)\u001b[0m\n\u001b[1;32m    882\u001b[0m           skip_conditionals=True)\n\u001b[1;32m    883\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 884\u001b[0;31m       \u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_state\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_cell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    885\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    886\u001b[0m     \u001b[0;31m# Keras cells always wrap state as list, even if it's a single tensor.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    868\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_keras_rnn_cell\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    869\u001b[0m       \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 870\u001b[0;31m     \u001b[0mcall_cell\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msequence_length\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn_cell_impl.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, state, scope, *args, **kwargs)\u001b[0m\n\u001b[1;32m    384\u001b[0m     \u001b[0;31m# method.  See the class docstring for more details.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m     return base_layer.Layer.__call__(\n\u001b[0;32m--> 386\u001b[0;31m         self, inputs, state, scope=scope, *args, **kwargs)\n\u001b[0m\u001b[1;32m    387\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/layers/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    546\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m       \u001b[0;31m# Actually call layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 548\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    549\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    822\u001b[0m           \u001b[0;31m# Build layer if applicable (if the `build` method has been\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    823\u001b[0m           \u001b[0;31m# overridden).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 824\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    825\u001b[0m           \u001b[0mcast_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    826\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_maybe_build\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2144\u001b[0m         \u001b[0;31m# operations.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2145\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaybe_init_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2146\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2147\u001b[0m       \u001b[0;31m# We must set self.built since user defined build functions are not\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2148\u001b[0m       \u001b[0;31m# constrained to set self.built.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(instance, input_shape)\u001b[0m\n\u001b[1;32m    304\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput_shape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m       \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_shapes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_tuples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 306\u001b[0;31m     \u001b[0moutput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    307\u001b[0m     \u001b[0;31m# Return shapes from `fn` as TensorShapes.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0moutput_shape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn_cell_impl.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, inputs_shape)\u001b[0m\n\u001b[1;32m    449\u001b[0m       raise ValueError(\"Expected inputs.shape[-1] to be known, saw shape: %s\" %\n\u001b[1;32m    450\u001b[0m                        str(inputs_shape))\n\u001b[0;32m--> 451\u001b[0;31m     \u001b[0m_check_supported_dtypes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0minput_depth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn_cell_impl.py\u001b[0m in \u001b[0;36m_check_supported_dtypes\u001b[0;34m(dtype)\u001b[0m\n\u001b[1;32m   1345\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1346\u001b[0m     raise ValueError(\"RNN cell only supports floating point inputs, \"\n\u001b[0;32m-> 1347\u001b[0;31m                      \"but saw dtype: %s\" % dtype)\n\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m: RNN cell only supports floating point inputs, but saw dtype: <dtype: 'int32'>"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iUXaTWR04KAo",
        "colab_type": "text"
      },
      "source": [
        "Note that we never used MAX_LENGTH in the code above: TF will iterate over however many time-steps you gave it.\n",
        "\n",
        "You can also use any pre-implemented RNN cell:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:27:12.981697Z",
          "start_time": "2018-08-13T20:27:12.977590Z"
        },
        "id": "qJiwYvEg4KAp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for obj in dir(tf.nn.rnn_cell) + dir(tf.contrib.rnn):\n",
        "    if obj.endswith('Cell'):\n",
        "        print(obj, end=\"\\t\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:27:13.168207Z",
          "start_time": "2018-08-13T20:27:12.986884Z"
        },
        "id": "lwBSii4y4KAr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_sequence = tf.placeholder(tf.int32, (None, None))\n",
        "\n",
        "inputs_embedded = embed_x(input_sequence)\n",
        "\n",
        "# standard cell returns hidden state as output!\n",
        "cell = tf.nn.rnn_cell.LSTMCell(rnn_num_units)\n",
        "\n",
        "state_sequence, last_state = tf.nn.dynamic_rnn(cell, inputs_embedded, dtype=tf.float32)\n",
        "\n",
        "s.run(tf.global_variables_initializer())\n",
        "\n",
        "print('LSTM hidden state for each step [batch,time,rnn_num_units]:')\n",
        "print(state_sequence.eval({input_sequence: to_matrix(names[:10], max_len=50)}).shape)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}